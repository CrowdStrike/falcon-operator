{{ if eq .Distro "gke" }}

## GKE Autopilot configuration

<details>
  <summary>Click to expand</summary>

### Configuring the AllowlistSynchronizer
Running Daemonset Pods with privileged access on GKE Autopilot requires special configurations due to default security restrictions. To enable these privileged Pods, you need to configure an AllowlistSynchronizer. This resource applies CrowdStrike specific WorkloadAllowlists to your cluster, which the GKE Autopilot validating webhook uses to approve Pod deployments based on their manifest spec and image digests. Follow these steps to properly configure the AllowlistSynchronizer:
Comment


1. Create a file named `allowlist-synchronizer.yaml` with the following contents:
```
apiVersion: auto.gke.io/v1
kind: AllowlistSynchronizer
metadata:
  name: crowdstrike-synchronizer
spec:
  allowlistPaths:
  - CrowdStrike/falcon-sensor/*
```
2. Apply the AllowlistSynchronizer to your cluster:
```
kubectl apply -f allowlist-synchronizer.yaml
```

3. Ensure the AllowlistSynchronizer is running:
```
kubectl get allowlistsynchronizers
```

4. Ensure the AllowlistSynchronizer has fetched the WorkloadAllowlist:
```
kubectl get workloadallowlists
```
An example output of the above command is:
```
NAME                                                  AGE
crowdstrike-falconsensor-cleanup-allowlist-v1.0.0     7d
crowdstrike-falconsensor-cleanup-allowlist-v1.0.1     7d
crowdstrike-falconsensor-cleanup-allowlist-v1.0.2     7d
crowdstrike-falconsensor-deploy-allowlist-v1.0.0      7d
crowdstrike-falconsensor-deploy-allowlist-v1.0.1      7d
crowdstrike-falconsensor-deploy-allowlist-v1.0.2      7d
crowdstrike-falconsensor-deploy-allowlist-v1.0.3      6h40m
crowdstrike-falconsensor-falconctl-allowlist-v1.0.0   7d
crowdstrike-falconsensor-falconctl-allowlist-v1.0.1   7d
```
#### WorkloadAllowlist Definitions
The WorkloadAllowlists serve the following purposes:
- crowdstrike-falconsensor-cleanup-allowlist-vX.X.X: Authorizes the Falcon Sensor Cleanup DaemonSet to operate within the cluster.
- crowdstrike-falconsensor-deploy-allowlist-vX.X.X: Permits the deployment and execution of the Falcon Sensor Deploy DaemonSet in the cluster environment.
- crowdstrike-falconsensor-falconctl-allowlist-vX.X.X: Enables the Falconctl job to run, facilitating sensor configuration and management tasks.

> [!NOTE]
> Additional information about AllowlistSynchronizer can be found here: [https://cloud.google.com/kubernetes-engine/docs/reference/crds/allowlistsynchronizer](https://cloud.google.com/kubernetes-engine/docs/reference/crds/allowlistsynchronizer)

#### Obtaining an Authorized Image
WorkloadAllowlists ensure that only authorized container images are deployed to pods by verifying their image digests. To view the list of approved image digests, execute the following command:
```
kubectl get workloadallowlists <crowdstrike-falconsensor-XXXXXXX-allowlist-vX.X.X>  -o=jsonpath='{range .containerImageDigests[*].imageDigests[*]}{@}{"\n"}{end}'
```
To obtain the Falcon Node sensor image, you have two options:

1. Pull directly from the CrowdStrike registry
2. Copy the image from the CrowdStrike registry to your private registry

For option 2, we provide an automation script to simplify the process:
[https://github.com/CrowdStrike/falcon-scripts/tree/main/bash/containers/falcon-container-sensor-pull](https://github.com/CrowdStrike/falcon-scripts/tree/main/bash/containers/falcon-container-sensor-pull)

When copying images to a private registry, it's crucial to preserve the image digest. We recommend using tools like Skopeo for this purpose, as they ensure the digest of the image remains the same after the transfer. Additionally, the usage of an image digest should be used in the deployment manifest when an private registry is used. Example:
```
apiVersion: falcon.crowdstrike.com/v1alpha1
kind: FalconNodeSensor
metadata:
  name: falcon-node-sensor
spec:
  falcon_api:
    client_id: <client_id>
    client_secret: <client_secret>
    cloud_region: autodiscover
node:
  image: private.registry/falcon-sensor:sha256:ef5b80182894bba37c23aeea2748683bde186914b28e193708e6919c2549d396
  imagePullSecrets:
    - name: internal-registry-secret
```

### Setting the PriorityClass

When you enable GKE Autopilot deployment in the Falcon Operator, this creates a new PriorityClass to ensure that the sensor DaemonSet has priority over other application pods. This means that it’s possible that some application pods are evicted or pushed back in the scheduling queue depending on cluster resources availability to accommodate sensor Pods. You can either allow the operator to deploy its own PriorityClass or specify an existing PriorityClass.

### Configuring the resource usage

GKE Autopilot enforces supported minimum and maximum values for the total resources requested by your deployment configuration and will adjust the limits and requests to be within the min/max range. GKE Autopilot lets you set requests but not limits, and will mutate the limits to match the request values.



```yaml
resources:
  requests:
    cpu: "250m"
  limits:
    cpu: "<mutates to match requests>"
```

To understand how GKE Autopilot adjusts limits, and the minimum and maximum resource requests, see [Google Cloud documentation: Minimum and maximum resource requests](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-resource-requests#min-max-requests).

The Falcon sensor resource usage depends on application workloads and therefore requires more resources if the sensor observes more events. The sensor defaults defined for memory and CPU are only for a successful sensor deployment. Consider adjusting the sensor memory and CPU within the allowed range enforced by GKE Autopilot to ensure the sensor deploys correctly.

> [!WARNING]
> Incorrect resource settings can lead to sensor deployment failure or a loss of clouded events. Avoid the following:
> * Setting requests or limits that are too low
> * Setting requests and limits that do not match ([more info](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-resource-requests#resource-limits))

If the sensor fails to start, it’s likely because the application workload requires more resources. If this is the case, set the resource requests to a value higher within the acceptable GKE Autopilot min/max range.
If you notice that the resource allocation is too high for the application workloads, lower the resource requests as needed.

You can retrieve a snapshot of your resource usage with `kubectl top`, or other resource monitoring like Datadog or Prometheus. For example, the following command will show your CPU and Memory resource usage in the `falcon-system` namespace.

```shell
kubectl top pod -n falcon-system
NAME                                   CPU(cores)   MEMORY(bytes)
falcon-helm-falcon-node-sensor-slsmg   498m         223Mi
```

The sensor resource limits are only enabled when `backend: bpf`, which is a requirement for GKE Autopilot.

### Enabling GKE Autopilot

<details>
  <summary>Click to expand</summary>

To enable GKE Autopilot and deploy the sensor running in user mode, configure the following settings:

1. Set the backend to run in user mode.
   ```yaml
   node:
     backend: bpf
   ```

2. Enable GKE Autopilot.
   ```yaml
   node:
     gke:
       autopilot: true
   ```

3. Optionally, provide a name for an existing priority class, or the operator will create one for you.
   ```yaml
   node:
     priorityClass:
       Name: my_custom_priorityclass
   ```

4. Based on your workload requirements, set the requests and limits. The default values for GKE Autopilot are `750m` CPU and `1.5Gi` memory. The minimum allowed values are `250m` CPU and `500Mi` memory:
   ```yaml
   node:
     resources:
       cpu: 750m
       memory: 1.5Gi
   ```
   > [!WARNING]
   > If you set the requests or limits too low, you can potentially cause the sensor deployment to fail or cause loss of clouded events.

Add the following toleration to deploy correctly on autopilot:

```yaml
    - effect: NoSchedule
      key: kubernetes.io/arch
      operator: Equal
      value: amd64
```

Putting it altogether, an example completed node sensor configuration for GKE Autopilot could look like the following:

```yaml
node:
  backend: bpf
  gke:
    autopilot: true
  resources:
    requests:
      cpu: 750m
      memory: 1.5Gi
  tolerations:
    - effect: NoSchedule
      operator: Equal
      key: kubernetes.io/arch
      value: amd64
```

</details>

</details>

{{- end -}}
